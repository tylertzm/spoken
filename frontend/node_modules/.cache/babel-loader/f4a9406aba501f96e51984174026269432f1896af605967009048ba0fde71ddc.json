{"ast":null,"code":"var _jsxFileName = \"/Users/tyler/Documents/SpeakNow/frontend/src/App.jsx\",\n  _s = $RefreshSig$();\nimport React, { useState, useEffect, useRef } from 'react';\nimport './styles.css';\nimport TranscriptionDisplay from './TranscriptionDisplay';\nimport webRTCService from './WebRTCService';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nfunction App() {\n  _s();\n  const [transcription, setTranscription] = useState('');\n  const [allTranscriptions, setAllTranscriptions] = useState([]);\n  const [imageUrls, setImageUrls] = useState({}); // Store images by chunkId\n  const [connectionStatus, setConnectionStatus] = useState('Connecting...');\n  const clearTranscriptionTimer = useRef(null);\n  useEffect(() => {\n    const componentId = Math.random().toString(36).substring(2, 11);\n    console.log('ðŸŽ¯ App component mounted with ID:', componentId, 'setting up WebRTC listener');\n    const handleWebRTCMessage = message => {\n      console.log('ðŸ“¨ Component', componentId, 'received WebRTC message:', message);\n      if (message.type === 'status') {\n        setConnectionStatus(message.data);\n      } else if (message.type === 'images') {\n        // Store images for the corresponding transcription\n        setImageUrls(prev => ({\n          ...prev,\n          [message.chunkId]: message.images\n        }));\n        console.log('ðŸ–¼ï¸ Received images for chunk:', message.chunkId, message.images);\n      } else if (message.type === 'transcription') {\n        const transcriptionText = message.data;\n\n        // Only update transcription if it's meaningful (not empty or \"No speech detected\")\n        if (transcriptionText && transcriptionText.trim() !== '' && transcriptionText !== '[No speech detected]' && !transcriptionText.includes('[Transcription error:')) {\n          console.log('âœ… Updating live transcription:', transcriptionText);\n          setTranscription(transcriptionText);\n\n          // Clear any existing timer\n          if (clearTranscriptionTimer.current) {\n            clearTimeout(clearTranscriptionTimer.current);\n          }\n\n          // Set a new timer to clear the transcription after 5 seconds of silence\n          clearTranscriptionTimer.current = setTimeout(() => {\n            console.log('â° Clearing transcription after timeout');\n            setTranscription('');\n          }, 5000);\n\n          // Add to history only if it's different from the last one\n          setAllTranscriptions(prev => {\n            if (prev.length === 0 || prev[0] !== transcriptionText) {\n              return [transcriptionText, ...prev];\n            }\n            return prev;\n          });\n        } else {\n          console.log('ðŸ”‡ Ignoring empty/error transcription:', transcriptionText);\n          // Don't update live transcription - keep the previous one visible\n        }\n      }\n    };\n\n    // Add listener - WebRTC streaming will start automatically\n    webRTCService.addListener(handleWebRTCMessage);\n    return () => {\n      console.log('ðŸ§¹ App component', componentId, 'unmounting, removing WebRTC listener');\n\n      // Clear any pending transcription timer\n      if (clearTranscriptionTimer.current) {\n        clearTimeout(clearTranscriptionTimer.current);\n      }\n      webRTCService.removeListener(handleWebRTCMessage);\n      // WebRTC streaming will stop automatically when no listeners remain\n    };\n  }, []); // Empty dependency array - only run once\n\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"App\",\n    children: /*#__PURE__*/_jsxDEV(\"header\", {\n      className: \"App-header\",\n      children: /*#__PURE__*/_jsxDEV(TranscriptionDisplay, {\n        transcription: transcription,\n        allTranscriptions: allTranscriptions,\n        connectionStatus: connectionStatus,\n        imageUrls: imageUrls\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 84,\n        columnNumber: 9\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 83,\n      columnNumber: 7\n    }, this)\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 82,\n    columnNumber: 5\n  }, this);\n}\n_s(App, \"ODL2icfUozUXI1wXq550+AAUJZw=\");\n_c = App;\nexport default App;\nvar _c;\n$RefreshReg$(_c, \"App\");","map":{"version":3,"names":["React","useState","useEffect","useRef","TranscriptionDisplay","webRTCService","jsxDEV","_jsxDEV","App","_s","transcription","setTranscription","allTranscriptions","setAllTranscriptions","imageUrls","setImageUrls","connectionStatus","setConnectionStatus","clearTranscriptionTimer","componentId","Math","random","toString","substring","console","log","handleWebRTCMessage","message","type","data","prev","chunkId","images","transcriptionText","trim","includes","current","clearTimeout","setTimeout","length","addListener","removeListener","className","children","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["/Users/tyler/Documents/SpeakNow/frontend/src/App.jsx"],"sourcesContent":["import React, { useState, useEffect, useRef } from 'react';\nimport './styles.css';\nimport TranscriptionDisplay from './TranscriptionDisplay';\nimport webRTCService from './WebRTCService';\n\nfunction App() {\n  const [transcription, setTranscription] = useState('');\n  const [allTranscriptions, setAllTranscriptions] = useState([]);\n  const [imageUrls, setImageUrls] = useState({});  // Store images by chunkId\n  const [connectionStatus, setConnectionStatus] = useState('Connecting...');\n  const clearTranscriptionTimer = useRef(null);\n\n  useEffect(() => {\n    const componentId = Math.random().toString(36).substring(2, 11);\n    console.log('ðŸŽ¯ App component mounted with ID:', componentId, 'setting up WebRTC listener');\n    \n    const handleWebRTCMessage = (message) => {\n      console.log('ðŸ“¨ Component', componentId, 'received WebRTC message:', message);\n      if (message.type === 'status') {\n        setConnectionStatus(message.data);\n      } else if (message.type === 'images') {\n        // Store images for the corresponding transcription\n        setImageUrls(prev => ({\n          ...prev,\n          [message.chunkId]: message.images\n        }));\n        console.log('ðŸ–¼ï¸ Received images for chunk:', message.chunkId, message.images);\n      } else if (message.type === 'transcription') {\n        const transcriptionText = message.data;\n        \n        // Only update transcription if it's meaningful (not empty or \"No speech detected\")\n        if (transcriptionText && \n            transcriptionText.trim() !== '' && \n            transcriptionText !== '[No speech detected]' &&\n            !transcriptionText.includes('[Transcription error:')) {\n          \n          console.log('âœ… Updating live transcription:', transcriptionText);\n          setTranscription(transcriptionText);\n          \n          // Clear any existing timer\n          if (clearTranscriptionTimer.current) {\n            clearTimeout(clearTranscriptionTimer.current);\n          }\n          \n          // Set a new timer to clear the transcription after 5 seconds of silence\n          clearTranscriptionTimer.current = setTimeout(() => {\n            console.log('â° Clearing transcription after timeout');\n            setTranscription('');\n          }, 5000);\n          \n          // Add to history only if it's different from the last one\n          setAllTranscriptions(prev => {\n            if (prev.length === 0 || prev[0] !== transcriptionText) {\n              return [transcriptionText, ...prev];\n            }\n            return prev;\n          });\n        } else {\n          console.log('ðŸ”‡ Ignoring empty/error transcription:', transcriptionText);\n          // Don't update live transcription - keep the previous one visible\n        }\n      }\n    };\n\n    // Add listener - WebRTC streaming will start automatically\n    webRTCService.addListener(handleWebRTCMessage);\n\n    return () => {\n      console.log('ðŸ§¹ App component', componentId, 'unmounting, removing WebRTC listener');\n      \n      // Clear any pending transcription timer\n      if (clearTranscriptionTimer.current) {\n        clearTimeout(clearTranscriptionTimer.current);\n      }\n      \n      webRTCService.removeListener(handleWebRTCMessage);\n      // WebRTC streaming will stop automatically when no listeners remain\n    };\n  }, []); // Empty dependency array - only run once\n\n  return (\n    <div className=\"App\">\n      <header className=\"App-header\">\n        <TranscriptionDisplay\n          transcription={transcription}\n          allTranscriptions={allTranscriptions}\n          connectionStatus={connectionStatus}\n          imageUrls={imageUrls}\n        />\n      </header>\n    </div>\n  );\n}\n\nexport default App;"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,SAAS,EAAEC,MAAM,QAAQ,OAAO;AAC1D,OAAO,cAAc;AACrB,OAAOC,oBAAoB,MAAM,wBAAwB;AACzD,OAAOC,aAAa,MAAM,iBAAiB;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAE5C,SAASC,GAAGA,CAAA,EAAG;EAAAC,EAAA;EACb,MAAM,CAACC,aAAa,EAAEC,gBAAgB,CAAC,GAAGV,QAAQ,CAAC,EAAE,CAAC;EACtD,MAAM,CAACW,iBAAiB,EAAEC,oBAAoB,CAAC,GAAGZ,QAAQ,CAAC,EAAE,CAAC;EAC9D,MAAM,CAACa,SAAS,EAAEC,YAAY,CAAC,GAAGd,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,CAAE;EACjD,MAAM,CAACe,gBAAgB,EAAEC,mBAAmB,CAAC,GAAGhB,QAAQ,CAAC,eAAe,CAAC;EACzE,MAAMiB,uBAAuB,GAAGf,MAAM,CAAC,IAAI,CAAC;EAE5CD,SAAS,CAAC,MAAM;IACd,MAAMiB,WAAW,GAAGC,IAAI,CAACC,MAAM,CAAC,CAAC,CAACC,QAAQ,CAAC,EAAE,CAAC,CAACC,SAAS,CAAC,CAAC,EAAE,EAAE,CAAC;IAC/DC,OAAO,CAACC,GAAG,CAAC,mCAAmC,EAAEN,WAAW,EAAE,4BAA4B,CAAC;IAE3F,MAAMO,mBAAmB,GAAIC,OAAO,IAAK;MACvCH,OAAO,CAACC,GAAG,CAAC,cAAc,EAAEN,WAAW,EAAE,0BAA0B,EAAEQ,OAAO,CAAC;MAC7E,IAAIA,OAAO,CAACC,IAAI,KAAK,QAAQ,EAAE;QAC7BX,mBAAmB,CAACU,OAAO,CAACE,IAAI,CAAC;MACnC,CAAC,MAAM,IAAIF,OAAO,CAACC,IAAI,KAAK,QAAQ,EAAE;QACpC;QACAb,YAAY,CAACe,IAAI,KAAK;UACpB,GAAGA,IAAI;UACP,CAACH,OAAO,CAACI,OAAO,GAAGJ,OAAO,CAACK;QAC7B,CAAC,CAAC,CAAC;QACHR,OAAO,CAACC,GAAG,CAAC,gCAAgC,EAAEE,OAAO,CAACI,OAAO,EAAEJ,OAAO,CAACK,MAAM,CAAC;MAChF,CAAC,MAAM,IAAIL,OAAO,CAACC,IAAI,KAAK,eAAe,EAAE;QAC3C,MAAMK,iBAAiB,GAAGN,OAAO,CAACE,IAAI;;QAEtC;QACA,IAAII,iBAAiB,IACjBA,iBAAiB,CAACC,IAAI,CAAC,CAAC,KAAK,EAAE,IAC/BD,iBAAiB,KAAK,sBAAsB,IAC5C,CAACA,iBAAiB,CAACE,QAAQ,CAAC,uBAAuB,CAAC,EAAE;UAExDX,OAAO,CAACC,GAAG,CAAC,gCAAgC,EAAEQ,iBAAiB,CAAC;UAChEtB,gBAAgB,CAACsB,iBAAiB,CAAC;;UAEnC;UACA,IAAIf,uBAAuB,CAACkB,OAAO,EAAE;YACnCC,YAAY,CAACnB,uBAAuB,CAACkB,OAAO,CAAC;UAC/C;;UAEA;UACAlB,uBAAuB,CAACkB,OAAO,GAAGE,UAAU,CAAC,MAAM;YACjDd,OAAO,CAACC,GAAG,CAAC,wCAAwC,CAAC;YACrDd,gBAAgB,CAAC,EAAE,CAAC;UACtB,CAAC,EAAE,IAAI,CAAC;;UAER;UACAE,oBAAoB,CAACiB,IAAI,IAAI;YAC3B,IAAIA,IAAI,CAACS,MAAM,KAAK,CAAC,IAAIT,IAAI,CAAC,CAAC,CAAC,KAAKG,iBAAiB,EAAE;cACtD,OAAO,CAACA,iBAAiB,EAAE,GAAGH,IAAI,CAAC;YACrC;YACA,OAAOA,IAAI;UACb,CAAC,CAAC;QACJ,CAAC,MAAM;UACLN,OAAO,CAACC,GAAG,CAAC,wCAAwC,EAAEQ,iBAAiB,CAAC;UACxE;QACF;MACF;IACF,CAAC;;IAED;IACA5B,aAAa,CAACmC,WAAW,CAACd,mBAAmB,CAAC;IAE9C,OAAO,MAAM;MACXF,OAAO,CAACC,GAAG,CAAC,kBAAkB,EAAEN,WAAW,EAAE,sCAAsC,CAAC;;MAEpF;MACA,IAAID,uBAAuB,CAACkB,OAAO,EAAE;QACnCC,YAAY,CAACnB,uBAAuB,CAACkB,OAAO,CAAC;MAC/C;MAEA/B,aAAa,CAACoC,cAAc,CAACf,mBAAmB,CAAC;MACjD;IACF,CAAC;EACH,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC;;EAER,oBACEnB,OAAA;IAAKmC,SAAS,EAAC,KAAK;IAAAC,QAAA,eAClBpC,OAAA;MAAQmC,SAAS,EAAC,YAAY;MAAAC,QAAA,eAC5BpC,OAAA,CAACH,oBAAoB;QACnBM,aAAa,EAAEA,aAAc;QAC7BE,iBAAiB,EAAEA,iBAAkB;QACrCI,gBAAgB,EAAEA,gBAAiB;QACnCF,SAAS,EAAEA;MAAU;QAAA8B,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OACtB;IAAC;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACI;EAAC;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACN,CAAC;AAEV;AAACtC,EAAA,CAvFQD,GAAG;AAAAwC,EAAA,GAAHxC,GAAG;AAyFZ,eAAeA,GAAG;AAAC,IAAAwC,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}