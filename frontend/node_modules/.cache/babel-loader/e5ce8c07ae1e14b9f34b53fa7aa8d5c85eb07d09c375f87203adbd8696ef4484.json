{"ast":null,"code":"var _jsxFileName = \"/Users/tyler/Documents/spoken/frontend/src/App.jsx\",\n  _s = $RefreshSig$();\nimport React, { useState, useEffect, useRef } from 'react';\nimport TranscriptionDisplay from './components/TranscriptionDisplay/TranscriptionDisplay';\nimport webRTCService from './WebRTCService';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nfunction App() {\n  _s();\n  const [transcription, setTranscription] = useState('');\n  const [allTranscriptions, setAllTranscriptions] = useState([]);\n  const [imageUrls, setImageUrls] = useState({}); // Store images by chunkId\n  const [connectionStatus, setConnectionStatus] = useState('Connecting...');\n  const [selectedLanguage, setSelectedLanguage] = useState('en'); // New state for language\n  const [cleanedTranscriptions, setCleanedTranscriptions] = useState([]); // NEW\n  const clearTranscriptionTimer = useRef(null);\n  useEffect(() => {\n    const componentId = Math.random().toString(36).substring(2, 11);\n    console.log('ðŸŽ¯ App component mounted with ID:', componentId, 'setting up WebRTC listener');\n    const handleWebRTCMessage = message => {\n      console.log('[App] Received WebRTC message:', message); // Debug log\n      if (message.type === 'status') {\n        setConnectionStatus(message.data);\n      } else if (message.type === 'images') {\n        // Store images for the corresponding transcription\n        setImageUrls(prev => ({\n          ...prev,\n          [message.chunkId]: message.images\n        }));\n        console.log('ðŸ–¼ï¸ Received images for chunk:', message.chunkId, message.images);\n      } else if (message.type === 'history') {\n        // Real-time streaming chunk for history log\n        const text = message.message;\n        // Only add to history if it's not the default chunk sent message\n        if (!text.startsWith('audioData chunk sent')) {\n          setAllTranscriptions(prev => {\n            if (text && (prev.length === 0 || prev[0] !== text)) {\n              return [text, ...prev];\n            }\n            return prev;\n          });\n        }\n      } else if (message.type === 'summary') {\n        // 3-second chunk for summary\n        setCleanedTranscriptions(prev => {\n          const text = message.message;\n          if (text && (prev.length === 0 || prev[0] !== text)) {\n            return [text, ...prev];\n          }\n          return prev;\n        });\n      } else if (message.type === 'transcription') {\n        console.log('[App] Received transcription message.data:', message.data); // Debug log\n        const transcriptionText = message.data;\n\n        // Only update transcription if it's meaningful (not empty or \"No speech detected\")\n        if (transcriptionText && transcriptionText.trim() !== '' && transcriptionText !== '[No speech detected]' && !transcriptionText.includes('[Transcription error:')) {\n          console.log('âœ… Updating live transcription:', transcriptionText);\n          setTranscription(transcriptionText);\n\n          // Clear any existing timer\n          if (clearTranscriptionTimer.current) {\n            clearTimeout(clearTranscriptionTimer.current);\n          }\n\n          // Set a new timer to clear the transcription after 5 seconds of silence\n          clearTranscriptionTimer.current = setTimeout(() => {\n            console.log('â° Clearing transcription after timeout');\n            setTranscription('');\n          }, 5000);\n\n          // Add to history only if it's different from the last one\n          setAllTranscriptions(prev => {\n            if (prev.length === 0 || prev[0] !== transcriptionText) {\n              return [transcriptionText, ...prev];\n            }\n            return prev;\n          });\n        } else {\n          console.log('ðŸ”‡ Ignoring empty/error transcription:', transcriptionText);\n          // Don't update live transcription - keep the previous one visible\n        }\n      }\n    };\n\n    // Add listener - WebRTC streaming will start automatically\n    webRTCService.addListener(handleWebRTCMessage);\n    return () => {\n      console.log('ðŸ§¹ App component', componentId, 'unmounting, removing WebRTC listener');\n\n      // Clear any pending transcription timer\n      if (clearTranscriptionTimer.current) {\n        clearTimeout(clearTranscriptionTimer.current);\n      }\n      webRTCService.removeListener(handleWebRTCMessage);\n      // WebRTC streaming will stop automatically when no listeners remain\n    };\n  }, []); // Empty dependency array - only run once\n\n  const handleLanguageChange = language => {\n    setSelectedLanguage(language);\n    console.log('ðŸ”„ Language changed to:', language);\n    webRTCService.setLanguage(language); // Update WebRTC service with new language\n  };\n\n  // Reconnect handler for connection status click\n  const handleReconnect = () => {\n    console.log('ðŸ”„ Reconnecting WebRTC...');\n    webRTCService.forceCleanup();\n    setTimeout(() => {\n      webRTCService.startAudioStreaming();\n    }, 500); // Small delay to ensure cleanup\n  };\n  useEffect(() => {\n    const cleaned = Array.from(new Set(allTranscriptions.map(t => typeof t === 'string' ? t.trim() : '').filter(Boolean)));\n    setCleanedTranscriptions(cleaned);\n  }, [allTranscriptions]);\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"App\",\n    children: /*#__PURE__*/_jsxDEV(\"header\", {\n      className: \"App-header\",\n      children: /*#__PURE__*/_jsxDEV(TranscriptionDisplay, {\n        transcription: transcription,\n        allTranscriptions: allTranscriptions,\n        connectionStatus: connectionStatus,\n        imageUrls: imageUrls,\n        onLanguageChange: handleLanguageChange,\n        onReconnect: handleReconnect,\n        cleanedTranscriptions: cleanedTranscriptions\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 131,\n        columnNumber: 9\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 130,\n      columnNumber: 7\n    }, this)\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 129,\n    columnNumber: 5\n  }, this);\n}\n_s(App, \"CiXmC9fw+ZHyP6hRtFQZ/aOrAKY=\");\n_c = App;\nexport default App;\nvar _c;\n$RefreshReg$(_c, \"App\");","map":{"version":3,"names":["React","useState","useEffect","useRef","TranscriptionDisplay","webRTCService","jsxDEV","_jsxDEV","App","_s","transcription","setTranscription","allTranscriptions","setAllTranscriptions","imageUrls","setImageUrls","connectionStatus","setConnectionStatus","selectedLanguage","setSelectedLanguage","cleanedTranscriptions","setCleanedTranscriptions","clearTranscriptionTimer","componentId","Math","random","toString","substring","console","log","handleWebRTCMessage","message","type","data","prev","chunkId","images","text","startsWith","length","transcriptionText","trim","includes","current","clearTimeout","setTimeout","addListener","removeListener","handleLanguageChange","language","setLanguage","handleReconnect","forceCleanup","startAudioStreaming","cleaned","Array","from","Set","map","t","filter","Boolean","className","children","onLanguageChange","onReconnect","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["/Users/tyler/Documents/spoken/frontend/src/App.jsx"],"sourcesContent":["import React, { useState, useEffect, useRef } from 'react';\nimport TranscriptionDisplay from './components/TranscriptionDisplay/TranscriptionDisplay';\nimport webRTCService from './WebRTCService';\n\nfunction App() {\n  const [transcription, setTranscription] = useState('');\n  const [allTranscriptions, setAllTranscriptions] = useState([]);\n  const [imageUrls, setImageUrls] = useState({});  // Store images by chunkId\n  const [connectionStatus, setConnectionStatus] = useState('Connecting...');\n  const [selectedLanguage, setSelectedLanguage] = useState('en'); // New state for language\n  const [cleanedTranscriptions, setCleanedTranscriptions] = useState([]); // NEW\n  const clearTranscriptionTimer = useRef(null);\n\n  useEffect(() => {\n    const componentId = Math.random().toString(36).substring(2, 11);\n    console.log('ðŸŽ¯ App component mounted with ID:', componentId, 'setting up WebRTC listener');\n    \n    const handleWebRTCMessage = (message) => {\n      console.log('[App] Received WebRTC message:', message); // Debug log\n      if (message.type === 'status') {\n        setConnectionStatus(message.data);\n      } else if (message.type === 'images') {\n        // Store images for the corresponding transcription\n        setImageUrls(prev => ({\n          ...prev,\n          [message.chunkId]: message.images\n        }));\n        console.log('ðŸ–¼ï¸ Received images for chunk:', message.chunkId, message.images);\n      } else if (message.type === 'history') {\n        // Real-time streaming chunk for history log\n        const text = message.message;\n        // Only add to history if it's not the default chunk sent message\n        if (!text.startsWith('audioData chunk sent')) {\n          setAllTranscriptions(prev => {\n            if (text && (prev.length === 0 || prev[0] !== text)) {\n              return [text, ...prev];\n            }\n            return prev;\n          });\n        }\n      } else if (message.type === 'summary') {\n        // 3-second chunk for summary\n        setCleanedTranscriptions(prev => {\n          const text = message.message;\n          if (text && (prev.length === 0 || prev[0] !== text)) {\n            return [text, ...prev];\n          }\n          return prev;\n        });\n      } else if (message.type === 'transcription') {\n        console.log('[App] Received transcription message.data:', message.data); // Debug log\n        const transcriptionText = message.data;\n        \n        // Only update transcription if it's meaningful (not empty or \"No speech detected\")\n        if (transcriptionText && \n            transcriptionText.trim() !== '' && \n            transcriptionText !== '[No speech detected]' &&\n            !transcriptionText.includes('[Transcription error:')) {\n          \n          console.log('âœ… Updating live transcription:', transcriptionText);\n          setTranscription(transcriptionText);\n          \n          // Clear any existing timer\n          if (clearTranscriptionTimer.current) {\n            clearTimeout(clearTranscriptionTimer.current);\n          }\n          \n          // Set a new timer to clear the transcription after 5 seconds of silence\n          clearTranscriptionTimer.current = setTimeout(() => {\n            console.log('â° Clearing transcription after timeout');\n            setTranscription('');\n          }, 5000);\n          \n          // Add to history only if it's different from the last one\n          setAllTranscriptions(prev => {\n            if (prev.length === 0 || prev[0] !== transcriptionText) {\n              return [transcriptionText, ...prev];\n            }\n            return prev;\n          });\n        } else {\n          console.log('ðŸ”‡ Ignoring empty/error transcription:', transcriptionText);\n          // Don't update live transcription - keep the previous one visible\n        }\n      }\n    };\n\n    // Add listener - WebRTC streaming will start automatically\n    webRTCService.addListener(handleWebRTCMessage);\n\n    return () => {\n      console.log('ðŸ§¹ App component', componentId, 'unmounting, removing WebRTC listener');\n      \n      // Clear any pending transcription timer\n      if (clearTranscriptionTimer.current) {\n        clearTimeout(clearTranscriptionTimer.current);\n      }\n      \n      webRTCService.removeListener(handleWebRTCMessage);\n      // WebRTC streaming will stop automatically when no listeners remain\n    };\n  }, []); // Empty dependency array - only run once\n\n  const handleLanguageChange = (language) => {\n    setSelectedLanguage(language);\n    console.log('ðŸ”„ Language changed to:', language);\n    webRTCService.setLanguage(language); // Update WebRTC service with new language\n  };\n\n  // Reconnect handler for connection status click\n  const handleReconnect = () => {\n    console.log('ðŸ”„ Reconnecting WebRTC...');\n    webRTCService.forceCleanup();\n    setTimeout(() => {\n      webRTCService.startAudioStreaming();\n    }, 500); // Small delay to ensure cleanup\n  };\n\n  useEffect(() => {\n    const cleaned = Array.from(new Set(\n      allTranscriptions\n        .map(t => (typeof t === 'string' ? t.trim() : ''))\n        .filter(Boolean)\n    ));\n    setCleanedTranscriptions(cleaned);\n  }, [allTranscriptions]);\n\n  return (\n    <div className=\"App\">\n      <header className=\"App-header\">\n        <TranscriptionDisplay\n          transcription={transcription}\n          allTranscriptions={allTranscriptions}\n          connectionStatus={connectionStatus}\n          imageUrls={imageUrls}\n          onLanguageChange={handleLanguageChange}\n          onReconnect={handleReconnect}\n          cleanedTranscriptions={cleanedTranscriptions}\n        />\n      </header>\n    </div>\n  );\n}\n\nexport default App;"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,SAAS,EAAEC,MAAM,QAAQ,OAAO;AAC1D,OAAOC,oBAAoB,MAAM,wDAAwD;AACzF,OAAOC,aAAa,MAAM,iBAAiB;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAE5C,SAASC,GAAGA,CAAA,EAAG;EAAAC,EAAA;EACb,MAAM,CAACC,aAAa,EAAEC,gBAAgB,CAAC,GAAGV,QAAQ,CAAC,EAAE,CAAC;EACtD,MAAM,CAACW,iBAAiB,EAAEC,oBAAoB,CAAC,GAAGZ,QAAQ,CAAC,EAAE,CAAC;EAC9D,MAAM,CAACa,SAAS,EAAEC,YAAY,CAAC,GAAGd,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,CAAE;EACjD,MAAM,CAACe,gBAAgB,EAAEC,mBAAmB,CAAC,GAAGhB,QAAQ,CAAC,eAAe,CAAC;EACzE,MAAM,CAACiB,gBAAgB,EAAEC,mBAAmB,CAAC,GAAGlB,QAAQ,CAAC,IAAI,CAAC,CAAC,CAAC;EAChE,MAAM,CAACmB,qBAAqB,EAAEC,wBAAwB,CAAC,GAAGpB,QAAQ,CAAC,EAAE,CAAC,CAAC,CAAC;EACxE,MAAMqB,uBAAuB,GAAGnB,MAAM,CAAC,IAAI,CAAC;EAE5CD,SAAS,CAAC,MAAM;IACd,MAAMqB,WAAW,GAAGC,IAAI,CAACC,MAAM,CAAC,CAAC,CAACC,QAAQ,CAAC,EAAE,CAAC,CAACC,SAAS,CAAC,CAAC,EAAE,EAAE,CAAC;IAC/DC,OAAO,CAACC,GAAG,CAAC,mCAAmC,EAAEN,WAAW,EAAE,4BAA4B,CAAC;IAE3F,MAAMO,mBAAmB,GAAIC,OAAO,IAAK;MACvCH,OAAO,CAACC,GAAG,CAAC,gCAAgC,EAAEE,OAAO,CAAC,CAAC,CAAC;MACxD,IAAIA,OAAO,CAACC,IAAI,KAAK,QAAQ,EAAE;QAC7Bf,mBAAmB,CAACc,OAAO,CAACE,IAAI,CAAC;MACnC,CAAC,MAAM,IAAIF,OAAO,CAACC,IAAI,KAAK,QAAQ,EAAE;QACpC;QACAjB,YAAY,CAACmB,IAAI,KAAK;UACpB,GAAGA,IAAI;UACP,CAACH,OAAO,CAACI,OAAO,GAAGJ,OAAO,CAACK;QAC7B,CAAC,CAAC,CAAC;QACHR,OAAO,CAACC,GAAG,CAAC,gCAAgC,EAAEE,OAAO,CAACI,OAAO,EAAEJ,OAAO,CAACK,MAAM,CAAC;MAChF,CAAC,MAAM,IAAIL,OAAO,CAACC,IAAI,KAAK,SAAS,EAAE;QACrC;QACA,MAAMK,IAAI,GAAGN,OAAO,CAACA,OAAO;QAC5B;QACA,IAAI,CAACM,IAAI,CAACC,UAAU,CAAC,sBAAsB,CAAC,EAAE;UAC5CzB,oBAAoB,CAACqB,IAAI,IAAI;YAC3B,IAAIG,IAAI,KAAKH,IAAI,CAACK,MAAM,KAAK,CAAC,IAAIL,IAAI,CAAC,CAAC,CAAC,KAAKG,IAAI,CAAC,EAAE;cACnD,OAAO,CAACA,IAAI,EAAE,GAAGH,IAAI,CAAC;YACxB;YACA,OAAOA,IAAI;UACb,CAAC,CAAC;QACJ;MACF,CAAC,MAAM,IAAIH,OAAO,CAACC,IAAI,KAAK,SAAS,EAAE;QACrC;QACAX,wBAAwB,CAACa,IAAI,IAAI;UAC/B,MAAMG,IAAI,GAAGN,OAAO,CAACA,OAAO;UAC5B,IAAIM,IAAI,KAAKH,IAAI,CAACK,MAAM,KAAK,CAAC,IAAIL,IAAI,CAAC,CAAC,CAAC,KAAKG,IAAI,CAAC,EAAE;YACnD,OAAO,CAACA,IAAI,EAAE,GAAGH,IAAI,CAAC;UACxB;UACA,OAAOA,IAAI;QACb,CAAC,CAAC;MACJ,CAAC,MAAM,IAAIH,OAAO,CAACC,IAAI,KAAK,eAAe,EAAE;QAC3CJ,OAAO,CAACC,GAAG,CAAC,4CAA4C,EAAEE,OAAO,CAACE,IAAI,CAAC,CAAC,CAAC;QACzE,MAAMO,iBAAiB,GAAGT,OAAO,CAACE,IAAI;;QAEtC;QACA,IAAIO,iBAAiB,IACjBA,iBAAiB,CAACC,IAAI,CAAC,CAAC,KAAK,EAAE,IAC/BD,iBAAiB,KAAK,sBAAsB,IAC5C,CAACA,iBAAiB,CAACE,QAAQ,CAAC,uBAAuB,CAAC,EAAE;UAExDd,OAAO,CAACC,GAAG,CAAC,gCAAgC,EAAEW,iBAAiB,CAAC;UAChE7B,gBAAgB,CAAC6B,iBAAiB,CAAC;;UAEnC;UACA,IAAIlB,uBAAuB,CAACqB,OAAO,EAAE;YACnCC,YAAY,CAACtB,uBAAuB,CAACqB,OAAO,CAAC;UAC/C;;UAEA;UACArB,uBAAuB,CAACqB,OAAO,GAAGE,UAAU,CAAC,MAAM;YACjDjB,OAAO,CAACC,GAAG,CAAC,wCAAwC,CAAC;YACrDlB,gBAAgB,CAAC,EAAE,CAAC;UACtB,CAAC,EAAE,IAAI,CAAC;;UAER;UACAE,oBAAoB,CAACqB,IAAI,IAAI;YAC3B,IAAIA,IAAI,CAACK,MAAM,KAAK,CAAC,IAAIL,IAAI,CAAC,CAAC,CAAC,KAAKM,iBAAiB,EAAE;cACtD,OAAO,CAACA,iBAAiB,EAAE,GAAGN,IAAI,CAAC;YACrC;YACA,OAAOA,IAAI;UACb,CAAC,CAAC;QACJ,CAAC,MAAM;UACLN,OAAO,CAACC,GAAG,CAAC,wCAAwC,EAAEW,iBAAiB,CAAC;UACxE;QACF;MACF;IACF,CAAC;;IAED;IACAnC,aAAa,CAACyC,WAAW,CAAChB,mBAAmB,CAAC;IAE9C,OAAO,MAAM;MACXF,OAAO,CAACC,GAAG,CAAC,kBAAkB,EAAEN,WAAW,EAAE,sCAAsC,CAAC;;MAEpF;MACA,IAAID,uBAAuB,CAACqB,OAAO,EAAE;QACnCC,YAAY,CAACtB,uBAAuB,CAACqB,OAAO,CAAC;MAC/C;MAEAtC,aAAa,CAAC0C,cAAc,CAACjB,mBAAmB,CAAC;MACjD;IACF,CAAC;EACH,CAAC,EAAE,EAAE,CAAC,CAAC,CAAC;;EAER,MAAMkB,oBAAoB,GAAIC,QAAQ,IAAK;IACzC9B,mBAAmB,CAAC8B,QAAQ,CAAC;IAC7BrB,OAAO,CAACC,GAAG,CAAC,yBAAyB,EAAEoB,QAAQ,CAAC;IAChD5C,aAAa,CAAC6C,WAAW,CAACD,QAAQ,CAAC,CAAC,CAAC;EACvC,CAAC;;EAED;EACA,MAAME,eAAe,GAAGA,CAAA,KAAM;IAC5BvB,OAAO,CAACC,GAAG,CAAC,2BAA2B,CAAC;IACxCxB,aAAa,CAAC+C,YAAY,CAAC,CAAC;IAC5BP,UAAU,CAAC,MAAM;MACfxC,aAAa,CAACgD,mBAAmB,CAAC,CAAC;IACrC,CAAC,EAAE,GAAG,CAAC,CAAC,CAAC;EACX,CAAC;EAEDnD,SAAS,CAAC,MAAM;IACd,MAAMoD,OAAO,GAAGC,KAAK,CAACC,IAAI,CAAC,IAAIC,GAAG,CAChC7C,iBAAiB,CACd8C,GAAG,CAACC,CAAC,IAAK,OAAOA,CAAC,KAAK,QAAQ,GAAGA,CAAC,CAAClB,IAAI,CAAC,CAAC,GAAG,EAAG,CAAC,CACjDmB,MAAM,CAACC,OAAO,CACnB,CAAC,CAAC;IACFxC,wBAAwB,CAACiC,OAAO,CAAC;EACnC,CAAC,EAAE,CAAC1C,iBAAiB,CAAC,CAAC;EAEvB,oBACEL,OAAA;IAAKuD,SAAS,EAAC,KAAK;IAAAC,QAAA,eAClBxD,OAAA;MAAQuD,SAAS,EAAC,YAAY;MAAAC,QAAA,eAC5BxD,OAAA,CAACH,oBAAoB;QACnBM,aAAa,EAAEA,aAAc;QAC7BE,iBAAiB,EAAEA,iBAAkB;QACrCI,gBAAgB,EAAEA,gBAAiB;QACnCF,SAAS,EAAEA,SAAU;QACrBkD,gBAAgB,EAAEhB,oBAAqB;QACvCiB,WAAW,EAAEd,eAAgB;QAC7B/B,qBAAqB,EAAEA;MAAsB;QAAA8C,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAC9C;IAAC;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACI;EAAC;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACN,CAAC;AAEV;AAAC5D,EAAA,CA1IQD,GAAG;AAAA8D,EAAA,GAAH9D,GAAG;AA4IZ,eAAeA,GAAG;AAAC,IAAA8D,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}